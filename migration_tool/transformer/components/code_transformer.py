import os

from openai import OpenAI

from migration_tool.transformer.components.instructions import *


class CodeTransformer:
    __COMMENT_GENERATED_BY_AI = "// TODO This code is generated by AI and NOT reviewed yet!"
    __DEFAULT_INSTRUCTION = INSTRUCTION_CONVERT_CODE_TO_SPRING

    @staticmethod
    def __read_file_to_string(file_path):
        try:
            with open(file_path, 'r') as file:
                file_contents = file.read()
            return file_contents
        except FileNotFoundError:
            print("The file does not exist.")
        except Exception as e:
            print("An error occurred:", e)

    @staticmethod
    def __write_file_to_string(file_path, raw_result):
        formatted_result_content = CodeTransformer.__format_result_content(raw_result)
        try:
            with open(file_path, "w") as file:
                file.write(formatted_result_content)
        except Exception as e:
            print("An error occurred:", e)

    @staticmethod
    def __format_result_content(raw_result):
        marker_start = "```java"
        marker_end = "```"
        index_start = raw_result.find(marker_start)
        formatted_result = raw_result[index_start + len(marker_start) + 1:]
        index_end = formatted_result.find(marker_end)
        formatted_result = formatted_result[:index_end]
        formatted_result = CodeTransformer.__COMMENT_GENERATED_BY_AI + "\n" + formatted_result
        return formatted_result

    def __init__(self):
        self.client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    def __process_command(self, command, last_response_content):
        print("Executing command: " + command)
        conversation = []
        if last_response_content is not None:
            conversation.append({
                "role": "assistant",
                "content": last_response_content
            })
        conversation.append({
            "role": "user",
            "content": command
        })
        response = self.client.chat.completions.create(
            model="gpt-4-turbo",
            temperature=0.1,
            messages=conversation,
        )
        return response.choices[0].message.content

    def transform_code(self, input_file_path, output_file_path, instructions=None):
        input_file_contents = self.__read_file_to_string(input_file_path)
        service_class_commands = [self.__DEFAULT_INSTRUCTION + input_file_contents]
        if instructions is not None:
            service_class_commands.extend(instructions)

        last_response_content = None
        for command in service_class_commands:
            last_response_content = self.__process_command(command, last_response_content)
            print(last_response_content)

        self.__write_file_to_string(output_file_path, last_response_content)
